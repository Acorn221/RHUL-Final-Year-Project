@article{LotteryTicket,
  author     = {Jonathan Frankle and
                Michael Carbin},
  title      = {The Lottery Ticket Hypothesis: Training Pruned Neural Networks},
  journal    = {CoRR},
  volume     = {abs/1803.03635},
  year       = {2018},
  url        = {http://arxiv.org/abs/1803.03635},
  eprinttype = {arXiv},
  eprint     = {1803.03635},
  timestamp  = {Mon, 13 Aug 2018 16:48:29 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1803-03635.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{N2PS,
  author  = {Augasta, M.Gethsiyal and Kathirvalavakumar, T.},
  year    = {2011},
  month   = {12},
  pages   = {241-258},
  title   = {A Novel Pruning Algorithm for Optimizing Feedforward Neural Network of Classification Problems},
  volume  = {34},
  journal = {Neural Processing Letters},
  doi     = {10.1007/s11063-011-9196-7}
}

@inproceedings{EmbeddedSystems,
  author    = {Zhang, Zhongpeng},
  booktitle = {2021 2nd International Conference on Computing and Data Science (CDS)},
  title     = {Model Pruning Techniques for Boosting the Inference Efficiency on Embedded Systems},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {119-124},
  doi       = {10.1109/CDS52072.2021.00027}
}

@article{DBLP:journals/corr/abs-2106-06955,
  author     = {Jaron Maene and
                Mingxiao Li and
                Marie{-}Francine Moens},
  title      = {Towards Understanding Iterative Magnitude Pruning: Why Lottery Tickets
                Win},
  journal    = {CoRR},
  volume     = {abs/2106.06955},
  year       = {2021},
  url        = {https://arxiv.org/abs/2106.06955},
  eprinttype = {arXiv},
  eprint     = {2106.06955},
  timestamp  = {Tue, 15 Jun 2021 16:35:15 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2106-06955.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2003-03033,
  author     = {Davis W. Blalock and
                Jose Javier Gonzalez Ortiz and
                Jonathan Frankle and
                John V. Guttag},
  title      = {What is the State of Neural Network Pruning?},
  journal    = {CoRR},
  volume     = {abs/2003.03033},
  year       = {2020},
  url        = {https://arxiv.org/abs/2003.03033},
  eprinttype = {arXiv},
  eprint     = {2003.03033},
  timestamp  = {Tue, 10 Mar 2020 13:33:48 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2003-03033.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/BabaeizadehSC16,
  author     = {Mohammad Babaeizadeh and
                Paris Smaragdis and
                Roy H. Campbell},
  title      = {NoiseOut: {A} Simple Way to Prune Neural Networks},
  journal    = {CoRR},
  volume     = {abs/1611.06211},
  year       = {2016},
  url        = {http://arxiv.org/abs/1611.06211},
  eprinttype = {arXiv},
  eprint     = {1611.06211},
  timestamp  = {Mon, 13 Aug 2018 16:47:45 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/BabaeizadehSC16.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2202-03844,
  author     = {Javier Poyatos and
                Daniel Molina and
                Aritz D. Martinez and
                Javier Del Ser and
                Francisco Herrera},
  title      = {EvoPruneDeepTL: An Evolutionary Pruning Model for Transfer Learning
                based Deep Neural Networks},
  journal    = {CoRR},
  volume     = {abs/2202.03844},
  year       = {2022},
  url        = {https://arxiv.org/abs/2202.03844},
  eprinttype = {arXiv},
  eprint     = {2202.03844},
  timestamp  = {Wed, 09 Feb 2022 15:43:35 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2202-03844.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{gupta2022global,
  title  = {Global Magnitude Pruning With Minimum Threshold Is All We Need},
  author = {Manas Gupta and Vishandi Rudy Keneta and Abhishek Vaidyanathan and Ritwik Kanodia and Efe Camci and Chuan-Sheng Foo and Jie Lin},
  year   = {2022},
  url    = {https://openreview.net/forum?id=jNB6vfl_680}
}

@misc{ShrinkBench,
  title = {Open source PyTorch library to facilitate development and standardized evaluation of neural network pruning methods.},
  url   = {https://github.com/JJGO/shrinkbench}
}

@misc{Keras,
  title = {Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano.},
  url   = {https://keras.io/}
}

@misc{PyTorch,
  title = {PyTorch is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing, primarily developed by Facebook's AI Research lab (FAIR).},
  url   = {https://pytorch.org/}
}

@misc{TensorFlow,
  title = {TensorFlow is an end-to-end open source platform for machine learning.},
  url   = {https://www.tensorflow.org/}
}

@misc{Jupyter,
  title = {JupyterLab is a web-based interactive development environment for Jupyter notebooks, code, and data.},
  url   = {https://jupyter.org/}
}

@misc{Matplotlib,
  title = {Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python.},
  url   = {https://matplotlib.org/}
}

@misc{Pandas,
  title = {Pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language.},
  url   = {https://pandas.pydata.org/}
}

@misc{RHULGitLab,
  title = {RHUL GitLab},
  url   = {https://gitlab.cim.rhul.ac.uk/}
}

@misc{GTX1070,
  title = {NVIDIA GeForce GTX 1070},
  url   = {https://www.nvidia.com/en-gb/geforce/products/10series/geforce-gtx-1070/}
}

@misc{ImageNet,
  title = {ImageNet},
  url   = {http://www.image-net.org/}
}

@misc{Trello,
  title = {Trello},
  url   = {https://trello.com/}
}

@misc{OxfordFlowers102,
  title = {Oxford Flowers 102},
  url   = {https://www.robots.ox.ac.uk/~vgg/data/flowers/102/}
}

@misc{AlzheimersDataset,
  title = {Alzheimer's Dataset},
  url   = {https://www.kaggle.com/datasets/uraninjo/augmented-alzheimer-mri-dataset}
}

@article{DBLP:journals/corr/abs-1905-02244,
  author     = {Andrew Howard and
                Mark Sandler and
                Grace Chu and
                Liang{-}Chieh Chen and
                Bo Chen and
                Mingxing Tan and
                Weijun Wang and
                Yukun Zhu and
                Ruoming Pang and
                Vijay Vasudevan and
                Quoc V. Le and
                Hartwig Adam},
  title      = {Searching for MobileNetV3},
  journal    = {CoRR},
  volume     = {abs/1905.02244},
  year       = {2019},
  url        = {http://arxiv.org/abs/1905.02244},
  eprinttype = {arXiv},
  eprint     = {1905.02244},
  timestamp  = {Thu, 27 May 2021 16:20:51 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1905-02244.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/HeZRS15,
  author     = {Kaiming He and
                Xiangyu Zhang and
                Shaoqing Ren and
                Jian Sun},
  title      = {Deep Residual Learning for Image Recognition},
  journal    = {CoRR},
  volume     = {abs/1512.03385},
  year       = {2015},
  url        = {http://arxiv.org/abs/1512.03385},
  eprinttype = {arXiv},
  eprint     = {1512.03385},
  timestamp  = {Wed, 17 Apr 2019 17:23:45 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/HeZRS15.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/SzegedyVISW15,
  author     = {Christian Szegedy and
                Vincent Vanhoucke and
                Sergey Ioffe and
                Jonathon Shlens and
                Zbigniew Wojna},
  title      = {Rethinking the Inception Architecture for Computer Vision},
  journal    = {CoRR},
  volume     = {abs/1512.00567},
  year       = {2015},
  url        = {http://arxiv.org/abs/1512.00567},
  eprinttype = {arXiv},
  eprint     = {1512.00567},
  timestamp  = {Mon, 13 Aug 2018 16:49:07 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/SzegedyVISW15.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{NeuralNetworkDiagram,
  title = {Neural Network Diagram},
  url   = {https://www.tibco.com/reference-center/what-is-a-neural-network}
}
@misc{ConfusionMatrix,
  title = {Confusion Matrix},
  url   = {https://towardsdatascience.com/confusion-matrix-for-your-multi-class-machine-learning-model-ff9aa3bf7826}
}


@article{DBLP:journals/corr/abs-2101-09336,
  author     = {Hadjer Benmeziane and
                Kaoutar El Maghraoui and
                Hamza Ouarnoughi and
                Sma{\"{\i}}l Niar and
                Martin Wistuba and
                Naigang Wang},
  title      = {A Comprehensive Survey on Hardware-Aware Neural Architecture Search},
  journal    = {CoRR},
  volume     = {abs/2101.09336},
  year       = {2021},
  url        = {https://arxiv.org/abs/2101.09336},
  eprinttype = {arXiv},
  eprint     = {2101.09336},
  timestamp  = {Sat, 30 Jan 2021 18:02:51 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2101-09336.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{Manjaro,
  title = {Manjaro Linux},
  url   = {https://manjaro.org/}
}

@misc{CUDA,
  title = {CUDA Toolkit Documentation},
  url   = {https://docs.nvidia.com/cuda/}
}

@article{10.3389/fneur.2021.640696,
  author   = {Vichianin, Yudthaphon and Khummongkol, Anutr and Chiewvit, Pipat and Raksthaput, Atthapon and Chaichanettee, Sunisa and Aoonkaew, Nuttapol and Senanarong, Vorapun},
  title    = {Accuracy of Support-Vector Machines for Diagnosis of Alzheimer's Disease, Using Volume of Brain Obtained by Structural MRI at Siriraj Hospital},
  journal  = {Frontiers in Neurology},
  volume   = {12},
  year     = {2021},
  url      = {https://www.frontiersin.org/articles/10.3389/fneur.2021.640696},
  doi      = {10.3389/fneur.2021.640696},
  issn     = {1664-2295},
  abstract = {Background: The determination of brain volumes using visual ratings is associated with an inherently low accuracy for the diagnosis of Alzheimer's disease (AD). A support-vector machine (SVM) is one of the machine learning techniques, which may be utilized as a classifier for various classification problems. This study exploratorily investigated the accuracy of SVM classification models for AD subjects using brain volume and various clinical data as features.Methods: The study was designed as a retrospective chart review. A total of 201 eligible subjects were recruited from the Memory Clinic at Siriraj Hospital, Thailand. Eighteen cases were excluded due to incomplete MRI data. Subjects were randomly assigned to a training group (AD = 46, normal = 46) and testing group (AD = 45, normal = 46) for SVM modeling and validation, respectively. The results in terms of accuracy and a receiver operating characteristic curve analysis are reported.Results: The highest accuracy for brain volumetry (62.64%) was found using the hippocampus as a single feature. A combination of clinical parameters as features provided accuracy ranging between 83 and 90%. However, a combination of brain volumetry and clinical parameters as features to the SVM models did not improve the accuracy of the result.Conclusions: In our study, the use of brain volumetry as SVM features provided low classification accuracy with the highest accuracy of 62.64% using the hippocampus volume alone. In contrast, the use of clinical parameters [Thai mental state examination score, controlled oral word association tests (animals; and letters K, S, and P), learning memory, clock-drawing test, and construction-praxis] as features for SVM models provided good accuracy between 83 and 90%.}
}
@inproceedings{5972513,
  author    = {Agarwal, Mayank and Mostafa, Javed},
  booktitle = {2011 9th International Workshop on Content-Based Multimedia Indexing (CBMI)},
  title     = {Content-based image retrieval for Alzheimer's disease detection},
  year      = {2011},
  volume    = {},
  number    = {},
  pages     = {13-18},
  doi       = {10.1109/CBMI.2011.5972513}
}
@misc{ContentBasedImageRetrieval,
  title = {Content-Based Image Retrieval Diagram},
  url   = {https://en.wikipedia.org/wiki/Content-based_image_retrieval}
}
@misc{CommitLint,
  title = {CommitLint},
  url   = {https://github.com/conventional-changelog/commitlint}
}

@misc{tmux,
  title = {tmux},
  url   = {https://github.com/tmux/tmux/wiki}
}

@misc{VsCode,
  title = {VsCode},
  url   = {https://en.wikipedia.org/wiki/Visual_Studio_Code}
}

@misc{Python,
  title = {Python},
  url   = {https://www.python.org/}
}
@misc{ILSVRC,
  title = {ILSVRC},
  url   = {http://www.image-net.org/challenges/LSVRC/}
}
@misc{PyTest,
  title = {PyTest},
  url   = {https://docs.pytest.org/en/stable/}
}
@misc{OASIS,
  title = {OASIS},
  url   = {https://oasis-brains.org/#data}
}
@InProceedings{Simonyan15,
  author       = "Karen Simonyan and Andrew Zisserman",
  title        = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
  booktitle    = "International Conference on Learning Representations",
  year         = "2015",
}
@misc{RTX3080,
  title = {RTX 3080},
  url   = {https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3080/}
}
@misc{OASISFactSheet,
  title = {OASIS-1 Fact Sheet},
  url   = {https://oasis-brains.org/files/oasis_cross-sectional_facts.pdf}
}
@misc{Clinica, 
  title = {Clinica},
  url   = {https://github.com/aramis-lab/clinica}
}
@article{SAMPERGONZALEZ2018504,
title = {Reproducible evaluation of classification methods in Alzheimer's disease: Framework and application to MRI and PET data},
journal = {NeuroImage},
volume = {183},
pages = {504-521},
year = {2018},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2018.08.042},
url = {https://www.sciencedirect.com/science/article/pii/S1053811918307407},
author = {Jorge Samper-González and Ninon Burgos and Simona Bottani and Sabrina Fontanella and Pascal Lu and Arnaud Marcoux and Alexandre Routier and Jérémy Guillon and Michael Bacci and Junhao Wen and Anne Bertrand and Hugo Bertin and Marie-Odile Habert and Stanley Durrleman and Theodoros Evgeniou and Olivier Colliot},
keywords = {Classification, Reproducibility, Alzheimer's disease, Magnetic resonance imaging, Positron emission tomography, Open-source},
abstract = {A large number of papers have introduced novel machine learning and feature extraction methods for automatic classification of Alzheimer's disease (AD). However, while the vast majority of these works use the public dataset ADNI for evaluation, they are difficult to reproduce because different key components of the validation are often not readily available. These components include selected participants and input data, image preprocessing and cross-validation procedures. The performance of the different approaches is also difficult to compare objectively. In particular, it is often difficult to assess which part of the method (e.g. preprocessing, feature extraction or classification algorithms) provides a real improvement, if any. In the present paper, we propose a framework for reproducible and objective classification experiments in AD using three publicly available datasets (ADNI, AIBL and OASIS). The framework comprises: i) automatic conversion of the three datasets into a standard format (BIDS); ii) a modular set of preprocessing pipelines, feature extraction and classification methods, together with an evaluation framework, that provide a baseline for benchmarking the different components. We demonstrate the use of the framework for a large-scale evaluation on 1960 participants using T1 MRI and FDG PET data. In this evaluation, we assess the influence of different modalities, preprocessing, feature types (regional or voxel-based features), classifiers, training set sizes and datasets. Performances were in line with the state-of-the-art. FDG PET outperformed T1 MRI for all classification tasks. No difference in performance was found for the use of different atlases, image smoothing, partial volume correction of FDG PET images, or feature type. Linear SVM and L2-logistic regression resulted in similar performance and both outperformed random forests. The classification performance increased along with the number of subjects used for training. Classifiers trained on ADNI generalized well to AIBL and OASIS. All the code of the framework and the experiments is publicly available: general-purpose tools have been integrated into the Clinica software (www.clinica.run) and the paper-specific code is available at: https://gitlab.icm-institute.org/aramislab/AD-ML.}
}

@Article{Gorgolewski2016,
author={Gorgolewski, Krzysztof J.
and Auer, Tibor
and Calhoun, Vince D.
and Craddock, R. Cameron
and Das, Samir
and Duff, Eugene P.
and Flandin, Guillaume
and Ghosh, Satrajit S.
and Glatard, Tristan
and Halchenko, Yaroslav O.
and Handwerker, Daniel A.
and Hanke, Michael
and Keator, David
and Li, Xiangrui
and Michael, Zachary
and Maumet, Camille
and Nichols, B. Nolan
and Nichols, Thomas E.
and Pellman, John
and Poline, Jean-Baptiste
and Rokem, Ariel
and Schaefer, Gunnar
and Sochat, Vanessa
and Triplett, William
and Turner, Jessica A.
and Varoquaux, Ga{\"e}l
and Poldrack, Russell A.},
title={The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments},
journal={Scientific Data},
year={2016},
month={Jun},
day={21},
volume={3},
number={1},
pages={160044},
abstract={The development of magnetic resonance imaging (MRI) techniques has defined modern neuroimaging. Since its inception, tens of thousands of studies using techniques such as functional MRI and diffusion weighted imaging have allowed for the non-invasive study of the brain. Despite the fact that MRI is routinely used to obtain data for neuroscience research, there has been no widely adopted standard for organizing and describing the data collected in an imaging experiment. This renders sharing and reusing data (within or between labs) difficult if not impossible and unnecessarily complicates the application of automatic pipelines and quality assurance protocols. To solve this problem, we have developed the Brain Imaging Data Structure (BIDS), a standard for organizing and describing MRI datasets. The BIDS standard uses file formats compatible with existing software, unifies the majority of practices already common in the field, and captures the metadata necessary for most common data processing operations.},
issn={2052-4463},
doi={10.1038/sdata.2016.44},
url={https://doi.org/10.1038/sdata.2016.44}
}

@misc{BIDS_metadata
  title = {BIDS MRI Metadata},
  url   = {https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/01-magnetic-resonance-imaging-data.html}
}