\documentclass{article}

% Language setting
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{mathptmx}
\usepackage{titlesec}
\usepackage{lipsum}
\usepackage{pgfgantt}
\usepackage{csquotes}
\usepackage{glossaries}
\usepackage[backend=bibtex]{biblatex}

\addbibresource{refs.bib}

% Setting the section title size and spacing
\titleformat{\section}{\LARGE\scshape}{\thesection}{1em}{}

% Set page size and margins
\usepackage[a4paper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\newacronym{ml}{ML}{Machine Learning}
\newacronym{dl}{DL}{Deep Learning}
\newacronym{nn}{NN}{Neural Network}
\newacronym{cnn}{CNN}{Convolutional Neural Network}


\newglossaryentry{TransferLearning}
{
  name="Transfer Learning",
  description={is is a method of applying a pre-trained model to a new problem.}
}

\font\titleFont=cmr12 at 26pt
\font\subtitleFont=cmr12 at 20pt

\title{\titleFont Comparing Pruning Algorithms on Image Classification Models After Transfer Learning}
\date{\Large \today}
\author{\subtitleFont James Arnott}

\begin{document}

\maketitle

\begin {center}
\noindent\rule{15cm}{0.4pt}
\end{center}

\vspace{1cm}

\begin{center}
	\begin{Large}
			CS3821 - BSc Final Year Project
			
			Comparison Of Machine Learning Algorithms

			Supervised by Li Zhang

			\vspace{0.6cm}

			Department Of Computer Science

			\vspace{0.2cm}

			Royal Holloway, University Of London
	\end{Large}
\end{center}


\pagebreak

\section{Abstract}
My final year project will be comparing different pruning algorithms for neural nets,
after using transfer learning on a variety of different pre-trained image classification models.

This is not just useful for lower powered embedded systems\cite{EmbeddedSystems},
where processing power is very limited, but also for larger systems,
where massive neural networks can be used to achieve very
high accuracy in classification but can be optimised to run faster
to be deployed on mass in real world applications, to increase
commercial viability.

There are lots of pre-trained models available, such as VGG16, ResNet50, InceptionV3,
and MobileNetV2, which I can use to perform transfer learning on. These models
have been trained on the datasets like ImageNet, which contain millions of images
and thousands of classes.

Transfer learning is the process of applying a pre-trained model to a new problem,
in this case, it will be specialising a pre-trained model to classify a specific set of images.
This is done by removing the final layers of the model and replacing it with a new layers
that will be trained on the new dataset.

Pruning is the process of removing weights, nodes or even whole layers from a neural network.
This is done to reduce the size of the network, and therefore the amount of memory and
computation required to run it.

When using transfer learning with a pre-trained model, there can be many
unnessasary weights in the network that are not required for the new task
which the transfer learning is being used for. This is where pruning can be used
to remove these weights and reduce the size of the network, significantly
optimising the network and even increasing the accuracy of the network.

There are many different pruning algorithms, and this project will hope to compare
them and their performance on a variety of different pre-trained models, after
transfer learning to identify a reduced set of entities.

From FFT pruning in 1965\cite{FFT} to iterative magnitude pruning in 2018\cite{LotteryTicket},
the algorithms are constantly being developed and they therefore need to be constantly re-evaluated
to compare their performances and to see if existing algorithms can be improved upon.

I will need to consider very carefully what the entities the network will try
to identify are, as I will want to avoid any bias in the data set, and
ensure that the network is trained on a diverse set of images to ensure there is no
overfitting. I will also need to ensure that there are similar entities that the
network can distinguish between, to ensure that the network is not too simple.

\pagebreak

\section{How i'm going to do it}

I will be using Jupyter Notebooks\cite{Jupyter} along with Python for this project, as 
Python is a very popular language for machine learning and deep learning and there are many
libraries available for it, such as PyTorch\cite{PyTorch} and Keras\cite{Keras}.

I am intending on using ShrinkBench\cite{ShrinkBench} to compare the pruning algorithms,
as it has been recommended in a recent paper which evaluated the current state of neural network pruning algorithms.\cite{DBLP:journals/corr/abs-2003-03033}.

After downloading the models and setting up the training and test data, I will need to
train the models with transfer learning. At this stage, I will also test the accuracy of the
models before pruning, to see how much accuracy is lost, or even gained after pruning.

I will then go one by one and setup the pruning algorithms for the models.
I'll need to note down the computational cost of pruning each model, as well as the
accuracy of the model after pruning, and the size of the model after pruning.

I will then compare the results of the pruning algorithms, and see which one is the best
for each model, and which one is the best overall.

I will use the python library Matplotlib\cite{Matplotlib} to plot the results of the pruning algorithms,
and I will likely use the python library Pandas\cite{Pandas} to store the results of the pruning algorithms.

All of the code will be stored in the RHUL GitLab\cite{RHULGitLab} repository.

I will attempt to use my GTX 1070 GPU\cite{GTX1070} to train the models as I have it available to me.



\pagebreak

% Got most of these from here https://keras.io/api/applications/
\subsection{The pre-trained models that I intend to use}
\begin{itemize}
	\item VGG16
	\item VGG19
	\item ResNet50V2
	\item ResNet101
	\item ResNet101v2
	\item InceptionV3
	\item InceptionResNetV2
	\item MobileNet
	\item MobileNetV2
	\item DenseNet121
	\item DenseNet169
\end{itemize}

\subsection{The pruning algorithms that I intend to use}
\begin{itemize}
	\item Global Magnitude Pruning \cite{gupta2022global}
	\item Iterative magnitude pruning (Lottery Ticket Hypothesis)\cite{LotteryTicket}
	\item NoiseOut\cite{DBLP:journals/corr/BabaeizadehSC16}
	\item EvoPruneDeepTL \cite{DBLP:journals/corr/abs-2202-03844}
	\item Random pruning
\end{itemize}

I am certain that for some of the pruning algorithms, I will have too significant problems getting working
so the pruning algorithms that I will use will be subject to change.

\pagebreak
\section{Timeline}

\begin{ganttchart}{1}{27}
\gantttitle{Term 1}{27} \\
\gantttitlelist{1,2,3,4,5,6,7,8,9}{3} \\
\ganttgroup{\small Research}{1}{8} \\
\ganttgroup{\small Implementation}{9}{16} \\
\ganttbar{\small Classification Models}{1}{5} \\
\ganttlinkedbar{\small Pruning Algorithms}{3}{8} \ganttnewline 
\ganttlinkedbar{\small Classification models}{9}{11} \ganttnewline
\ganttlinkedbar{\small Transfer Learning}{10}{13} \ganttnewline
\ganttlinkedbar{\small Pruning Algorithms models}{12}{16} \ganttnewline
\ganttmilestone{\small Algorithms can be ran}{16} \ganttnewline
\ganttlinkedbar{\small Comparing Algorithms}{18}{25} \ganttnewline
\ganttlinkedbar{\small Report/Presentation}{25}{27}
\ganttlink{elem6}{elem7}
\end{ganttchart}

\subsection{Research Models}

Here, I will the pre-trained research models that I will use, along with the pruning algorithms I can implement with them. I will also research how to do transfer learning with the models I want to use for the comparisons.

\subsection{Implementation}

Here I will setup the models and make sure I can run them, the transfer learning will also be done here to specialise the models so they are trained to identify a specific subset of entities.

I will also setup the pruning algorithms to see how effective they are.

\subsection{Comparing Algorithms}

Here I will write scripts to compare the models after training and after pruning. I have allocated a lot of time to this as I will likely need to debug problems I have had with implementation, then I'll need to find good metrics which I can compare the models performance and efficiency with.

\subsection{Report/Presentation}

Here is where I will prepare the for the interim report and presentation.
I will hopefully have the models running and have applied the transfer learning, 
and have some results from the pruning algorithms.

\pagebreak
\begin{ganttchart}{1}{22}
\gantttitle{Term 2}{22} \\
\gantttitlelist{1,...,11}{2} \\
\ganttgroup{\small Evaluate The Comparison}{1}{8} \\
\ganttgroup{\small Optimise The Models}{9}{15} \\
\ganttbar{\small Compare Performance}{1}{5} \\
\ganttlinkedbar{\small Identify Problems}{3}{8} \ganttnewline 
\ganttlinkedbar{\small Try and Fix the problems}{9}{13} \ganttnewline
\ganttlinkedbar{\small Optimise For Efficiency}{10}{15} \ganttnewline
\ganttmilestone{\small MVP}{15} \ganttnewline
\ganttlinkedbar{\small Refactor the code}{16}{20} \ganttnewline
\ganttlinkedbar{\small Finish Report/Presentation}{18}{22}
\ganttlink{elem5}{elem6}
\end{ganttchart}

\subsection{Evaluate The Comparison}

Here I will try and find anomalies in my results and attempt to find fixes for the optimisation, I am likely to have misconfigured one of the models in the transfer learning or pruning and this is where I will hopefully identify where.

\subsection{Optimise The Models}

I will hopefully optimise the models here, after adjusting the transfer learning parameters and the pruning algorithm parameters. This may not be required however I assume with machine learning, there are always likely to be possible improvements.

\subsection{Finalising}

Refactoring the code should hopefully not be too complex and I should aim to keep everything in a relatively strict format throughout the project. The report I write and the presentation I make should be quite a big task with the time I have allocated, however it should be manageable and I will aim to keep my report updated throughout the project.

\pagebreak
\section{Risks and Mitigations}
With machine learning, I know there are many risks that many different aspects of training, pruning and testing can all go wrong.

\subsection{Problems with finding training data for transfer learning}
There can be problems with finding good data sets for the entities that I end up transfer learning with. As I have not decided what to use transfer learning for I can decide what would be the best data set and decide to transfer learn to that. This allows me to be more flexible and gives this project the highest chance of success.

\subsection{Problems with getting models to work}
As I want to use a few different models, the minimum ideally would be 10, I may have problems getting the models to work in the environment I want to use for all the models. This is not a huge issue as there are many tutorials online which I can follow to setup the models.

\subsection{Implementing the pruning algorithms}
This is the biggest risk to the project, I have very limited experience with machine learning and no experience at all with pruning models. I have a basic understanding about how pruning is supposed to work however I will be relying on tutorials primarily for the implementation of the algorithms and this is likely to be the most time consuming part of the project.

\subsection{Limitations of my available computing resources}
I may end up requiring extra computing resources for running some of the training and pruning algorithms.
I will need to be careful with the amount of data I use for training and pruning as I do not have a lot of computing resources available to me.
I can also use google cloud to run the models on a virtual machine if I need to that have more power.

\subsection{Problems with testing}
Throughout the project, I will need to compare the performance of the models, which is not too difficult as I can just have a test data set to compare them against. Testing the model's size would not be too difficult either as I could just use the model's file sizes, however, I am not yet confident as to how I will compare the models computational demand.

\subsection{Problems with managing my time throughout the project}
I cannot be certain how long each task will take, and I may end up spending too much time on one task and not enough on another.
This is a risk that I will need to be aware of throughout the project and I shall mitigate the risks by asking for help when I need it, to ensure I can progress in accordance with the project plan and I will need to learn more about how neural networks work 
and how to optimise them.

\pagebreak

\printbibliography

\end{document}