@article{LotteryTicket,
  author     = {Jonathan Frankle and
                Michael Carbin},
  title      = {The Lottery Ticket Hypothesis: Training Pruned Neural Networks},
  journal    = {CoRR},
  volume     = {abs/1803.03635},
  year       = {2018},
  url        = {http://arxiv.org/abs/1803.03635},
  eprinttype = {arXiv},
  eprint     = {1803.03635},
  timestamp  = {Mon, 13 Aug 2018 16:48:29 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1803-03635.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{N2PS,
  author  = {Augasta, M.Gethsiyal and Kathirvalavakumar, T.},
  year    = {2011},
  month   = {12},
  pages   = {241-258},
  title   = {A Novel Pruning Algorithm for Optimizing Feedforward Neural Network of Classification Problems},
  volume  = {34},
  journal = {Neural Processing Letters},
  doi     = {10.1007/s11063-011-9196-7}
}

@inproceedings{EmbeddedSystems,
  author    = {Zhang, Zhongpeng},
  booktitle = {2021 2nd International Conference on Computing and Data Science (CDS)},
  title     = {Model Pruning Techniques for Boosting the Inference Efficiency on Embedded Systems},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {119-124},
  doi       = {10.1109/CDS52072.2021.00027}
}

@article{DBLP:journals/corr/abs-2106-06955,
  author     = {Jaron Maene and
                Mingxiao Li and
                Marie{-}Francine Moens},
  title      = {Towards Understanding Iterative Magnitude Pruning: Why Lottery Tickets
                Win},
  journal    = {CoRR},
  volume     = {abs/2106.06955},
  year       = {2021},
  url        = {https://arxiv.org/abs/2106.06955},
  eprinttype = {arXiv},
  eprint     = {2106.06955},
  timestamp  = {Tue, 15 Jun 2021 16:35:15 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2106-06955.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2003-03033,
  author     = {Davis W. Blalock and
                Jose Javier Gonzalez Ortiz and
                Jonathan Frankle and
                John V. Guttag},
  title      = {What is the State of Neural Network Pruning?},
  journal    = {CoRR},
  volume     = {abs/2003.03033},
  year       = {2020},
  url        = {https://arxiv.org/abs/2003.03033},
  eprinttype = {arXiv},
  eprint     = {2003.03033},
  timestamp  = {Tue, 10 Mar 2020 13:33:48 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2003-03033.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/BabaeizadehSC16,
  author     = {Mohammad Babaeizadeh and
                Paris Smaragdis and
                Roy H. Campbell},
  title      = {NoiseOut: {A} Simple Way to Prune Neural Networks},
  journal    = {CoRR},
  volume     = {abs/1611.06211},
  year       = {2016},
  url        = {http://arxiv.org/abs/1611.06211},
  eprinttype = {arXiv},
  eprint     = {1611.06211},
  timestamp  = {Mon, 13 Aug 2018 16:47:45 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/BabaeizadehSC16.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2202-03844,
  author     = {Javier Poyatos and
                Daniel Molina and
                Aritz D. Martinez and
                Javier Del Ser and
                Francisco Herrera},
  title      = {EvoPruneDeepTL: An Evolutionary Pruning Model for Transfer Learning
                based Deep Neural Networks},
  journal    = {CoRR},
  volume     = {abs/2202.03844},
  year       = {2022},
  url        = {https://arxiv.org/abs/2202.03844},
  eprinttype = {arXiv},
  eprint     = {2202.03844},
  timestamp  = {Wed, 09 Feb 2022 15:43:35 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2202-03844.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{gupta2022global,
  title  = {Global Magnitude Pruning With Minimum Threshold Is All We Need},
  author = {Manas Gupta and Vishandi Rudy Keneta and Abhishek Vaidyanathan and Ritwik Kanodia and Efe Camci and Chuan-Sheng Foo and Jie Lin},
  year   = {2022},
  url    = {https://openreview.net/forum?id=jNB6vfl_680}
}

@misc{ShrinkBench,
  title = {Open source PyTorch library to facilitate development and standardized evaluation of neural network pruning methods.},
  url   = {https://github.com/JJGO/shrinkbench}
}

@misc{Keras,
  title = {Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano.},
  url   = {https://keras.io/}
}

@misc{PyTorch,
  title = {PyTorch is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing, primarily developed by Facebook's AI Research lab (FAIR).},
  url   = {https://pytorch.org/}
}

@misc{TensorFlow,
  title = {TensorFlow is an end-to-end open source platform for machine learning.},
  url   = {https://www.tensorflow.org/}
}

@misc{Jupyter,
  title = {JupyterLab is a web-based interactive development environment for Jupyter notebooks, code, and data.},
  url   = {https://jupyter.org/}
}

@misc{Matplotlib,
  title = {Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python.},
  url   = {https://matplotlib.org/}
}

@misc{Pandas,
  title = {Pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language.},
  url   = {https://pandas.pydata.org/}
}

@misc{RHULGitLab,
  title = {RHUL GitLab},
  url   = {https://gitlab.cim.rhul.ac.uk/}
}

@misc{GTX1070,
  title = {NVIDIA GeForce GTX 1070},
  url   = {https://www.nvidia.com/en-gb/geforce/products/10series/geforce-gtx-1070/}
}

@misc{ImageNet,
  title = {ImageNet},
  url   = {http://www.image-net.org/}
}

@misc{Trello,
  title = {Trello},
  url   = {https://trello.com/}
}

@misc{OxfordFlowers102,
  title = {Oxford Flowers 102},
  url   = {https://www.robots.ox.ac.uk/~vgg/data/flowers/102/}
}

@misc{AlzheimersDataset,
  title = {Alzheimer's Dataset},
  url   = {https://www.kaggle.com/datasets/uraninjo/augmented-alzheimer-mri-dataset}
}

@article{DBLP:journals/corr/abs-1905-02244,
  author     = {Andrew Howard and
                Mark Sandler and
                Grace Chu and
                Liang{-}Chieh Chen and
                Bo Chen and
                Mingxing Tan and
                Weijun Wang and
                Yukun Zhu and
                Ruoming Pang and
                Vijay Vasudevan and
                Quoc V. Le and
                Hartwig Adam},
  title      = {Searching for MobileNetV3},
  journal    = {CoRR},
  volume     = {abs/1905.02244},
  year       = {2019},
  url        = {http://arxiv.org/abs/1905.02244},
  eprinttype = {arXiv},
  eprint     = {1905.02244},
  timestamp  = {Thu, 27 May 2021 16:20:51 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1905-02244.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/HeZRS15,
  author     = {Kaiming He and
                Xiangyu Zhang and
                Shaoqing Ren and
                Jian Sun},
  title      = {Deep Residual Learning for Image Recognition},
  journal    = {CoRR},
  volume     = {abs/1512.03385},
  year       = {2015},
  url        = {http://arxiv.org/abs/1512.03385},
  eprinttype = {arXiv},
  eprint     = {1512.03385},
  timestamp  = {Wed, 17 Apr 2019 17:23:45 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/HeZRS15.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/SzegedyVISW15,
  author     = {Christian Szegedy and
                Vincent Vanhoucke and
                Sergey Ioffe and
                Jonathon Shlens and
                Zbigniew Wojna},
  title      = {Rethinking the Inception Architecture for Computer Vision},
  journal    = {CoRR},
  volume     = {abs/1512.00567},
  year       = {2015},
  url        = {http://arxiv.org/abs/1512.00567},
  eprinttype = {arXiv},
  eprint     = {1512.00567},
  timestamp  = {Mon, 13 Aug 2018 16:49:07 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/SzegedyVISW15.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{NeuralNetworkDiagram,
  title = {Neural Network Diagram},
  url   = {https://www.tibco.com/reference-center/what-is-a-neural-network}
}
@misc{ConfusionMatrix,
  title = {Confusion Matrix},
  url   = {https://towardsdatascience.com/confusion-matrix-for-your-multi-class-machine-learning-model-ff9aa3bf7826}
}


@article{DBLP:journals/corr/abs-2101-09336,
  author     = {Hadjer Benmeziane and
                Kaoutar El Maghraoui and
                Hamza Ouarnoughi and
                Sma{\"{\i}}l Niar and
                Martin Wistuba and
                Naigang Wang},
  title      = {A Comprehensive Survey on Hardware-Aware Neural Architecture Search},
  journal    = {CoRR},
  volume     = {abs/2101.09336},
  year       = {2021},
  url        = {https://arxiv.org/abs/2101.09336},
  eprinttype = {arXiv},
  eprint     = {2101.09336},
  timestamp  = {Sat, 30 Jan 2021 18:02:51 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2101-09336.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{Manjaro,
  title = {Manjaro Linux},
  url   = {https://manjaro.org/}
}

@misc{CUDA,
  title = {CUDA Toolkit Documentation},
  url   = {https://docs.nvidia.com/cuda/}
}

@inproceedings{10.1007/3-540-61123-1_173,
  author    = {Fleck, Margaret M.
               and Forsyth, David A.
               and Bregler, Chris},
  editor    = {Buxton, Bernard
               and Cipolla, Roberto},
  title     = {Finding naked people},
  booktitle = {Computer Vision --- ECCV '96},
  year      = {1996},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {593--602},
  abstract  = {This paper demonstrates a content-based retrieval strategy that can tell whether there are naked people present in an image. No manual intervention is required. The approach combines color and texture properties to obtain an effective mask for skin regions. The skin mask is shown to be effective for a wide range of shades and colors of skin. These skin regions are then fed to a specialized grouper, which attempts to group a human figure using geometric constraints on human structure. This approach introduces a new view of object recognition, where an object model is an organized collection of grouping hints obtained from a combination of constraints on geometric properties such as the structure of individual parts, and the relationships between parts, and constraints on color and texture. The system is demonstrated to have 60{\%} precision and 52{\%} recall on a test set of 138 uncontrolled images of naked people, mostly obtained from the internet, and 1401 assorted control images, drawn from a wide collection of sources.},
  isbn      = {978-3-540-49950-3}
}

@article{10.3389/fneur.2021.640696,
  author   = {Vichianin, Yudthaphon and Khummongkol, Anutr and Chiewvit, Pipat and Raksthaput, Atthapon and Chaichanettee, Sunisa and Aoonkaew, Nuttapol and Senanarong, Vorapun},
  title    = {Accuracy of Support-Vector Machines for Diagnosis of Alzheimer's Disease, Using Volume of Brain Obtained by Structural MRI at Siriraj Hospital},
  journal  = {Frontiers in Neurology},
  volume   = {12},
  year     = {2021},
  url      = {https://www.frontiersin.org/articles/10.3389/fneur.2021.640696},
  doi      = {10.3389/fneur.2021.640696},
  issn     = {1664-2295},
  abstract = {Background: The determination of brain volumes using visual ratings is associated with an inherently low accuracy for the diagnosis of Alzheimer's disease (AD). A support-vector machine (SVM) is one of the machine learning techniques, which may be utilized as a classifier for various classification problems. This study exploratorily investigated the accuracy of SVM classification models for AD subjects using brain volume and various clinical data as features.Methods: The study was designed as a retrospective chart review. A total of 201 eligible subjects were recruited from the Memory Clinic at Siriraj Hospital, Thailand. Eighteen cases were excluded due to incomplete MRI data. Subjects were randomly assigned to a training group (AD = 46, normal = 46) and testing group (AD = 45, normal = 46) for SVM modeling and validation, respectively. The results in terms of accuracy and a receiver operating characteristic curve analysis are reported.Results: The highest accuracy for brain volumetry (62.64%) was found using the hippocampus as a single feature. A combination of clinical parameters as features provided accuracy ranging between 83 and 90%. However, a combination of brain volumetry and clinical parameters as features to the SVM models did not improve the accuracy of the result.Conclusions: In our study, the use of brain volumetry as SVM features provided low classification accuracy with the highest accuracy of 62.64% using the hippocampus volume alone. In contrast, the use of clinical parameters [Thai mental state examination score, controlled oral word association tests (animals; and letters K, S, and P), learning memory, clock-drawing test, and construction-praxis] as features for SVM models provided good accuracy between 83 and 90%.}
}
@inproceedings{5972513,
  author    = {Agarwal, Mayank and Mostafa, Javed},
  booktitle = {2011 9th International Workshop on Content-Based Multimedia Indexing (CBMI)},
  title     = {Content-based image retrieval for Alzheimer's disease detection},
  year      = {2011},
  volume    = {},
  number    = {},
  pages     = {13-18},
  doi       = {10.1109/CBMI.2011.5972513}
}
@misc{ContentBasedImageRetrieval,
  title = {Content-Based Image Retrieval Diagram},
  url   = {https://en.wikipedia.org/wiki/Content-based_image_retrieval}
}
@misc{CommitLint,
  title = {CommitLint},
  url   = {https://github.com/conventional-changelog/commitlint}
}

@misc{tmux,
  title = {tmux},
  url   = {https://github.com/tmux/tmux/wiki}
}

@misc{VsCode,
  title = {VsCode},
  url   = {https://en.wikipedia.org/wiki/Visual_Studio_Code}
}

@misc{Python,
  title = {Python},
  url   = {https://www.python.org/}
}
@misc{ILSVRC,
  title = {ILSVRC},
  url   = {http://www.image-net.org/challenges/LSVRC/}
}